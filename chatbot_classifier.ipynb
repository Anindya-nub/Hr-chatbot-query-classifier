{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anindya-nub/Hr-chatbot-query-classifier/blob/main/chatbot_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfKJ6C7_IaFt"
      },
      "outputs": [],
      "source": [
        "# Define category mapping\n",
        "category_mapping = {\n",
        "    0: \"Leaves\",\n",
        "    1: \"Payroll\",\n",
        "    2: \"Healthcare\",\n",
        "    3: \"Recruitment\",\n",
        "    4: \"Training and Development\",\n",
        "    5: \"Performance Management\",\n",
        "    6: \"Employee Relations\",\n",
        "    7: \"Benefits\"\n",
        "}\n",
        "\n",
        "# Dataset: List of questions and corresponding labels (categories)\n",
        "sentences = [\n",
        "    # Leaves\n",
        "    \"How can I apply for maternity leave?\",\n",
        "    \"What is the process for requesting sick leave?\",\n",
        "    \"Can I carry forward my unused leave to the next year?\",\n",
        "    \"How many days of casual leave am I entitled to per year?\",\n",
        "    \"What is the policy on leave without pay?\",\n",
        "    \"How do I check my remaining leave balance?\",\n",
        "    \"Are there any restrictions on taking multiple leaves consecutively?\",\n",
        "    \"How do I cancel a leave that I have already applied for?\",\n",
        "    \"What documents are required for medical leave?\",\n",
        "    \"Can I take a half-day leave?\",\n",
        "    \"How does the company handle leaves during public holidays?\",\n",
        "    \"Can I apply for leave during my notice period?\",\n",
        "    \"What is the company's policy on paternity leave?\",\n",
        "    \"Is there an option to encash unused leaves?\",\n",
        "    \"How soon do I need to inform my manager about my leave plans?\",\n",
        "    \"What is the procedure for availing leave during an emergency?\",\n",
        "    \"Do I need to submit a medical certificate for short-term sick leave?\",\n",
        "    \"Can I adjust my leaves against overtime hours worked?\",\n",
        "    \"How does the company calculate leave balance for new joiners?\",\n",
        "    \"Are there any special leaves for marriage or bereavement?\",\n",
        "\n",
        "    # Payroll\n",
        "    \"When will my salary be credited this month?\",\n",
        "    \"How can I get a copy of my payslip?\",\n",
        "    \"What are the deductions mentioned in my payslip?\",\n",
        "    \"How do I update my bank details for salary deposits?\",\n",
        "    \"When will my salary increase after the performance review?\",\n",
        "    \"How is overtime calculated and paid?\",\n",
        "    \"What is the process for claiming travel allowances?\",\n",
        "    \"Why was there a deduction in my salary this month?\",\n",
        "    \"How are bonuses and incentives calculated?\",\n",
        "    \"What is the tax deduction on my salary?\",\n",
        "    \"How do I change my tax declaration for payroll purposes?\",\n",
        "    \"How can I view my previous months' salary details?\",\n",
        "    \"What should I do if there is an error in my salary payment?\",\n",
        "    \"How is leave encashment processed in payroll?\",\n",
        "    \"Can I get an advance on my salary?\",\n",
        "    \"How are reimbursements handled in the payroll process?\",\n",
        "    \"How do I check my Provident Fund (PF) balance?\",\n",
        "    \"What is the Gratuity amount mentioned in my CTC?\",\n",
        "    \"How do I submit investment proofs for tax exemption?\",\n",
        "    \"Are there any salary revisions or bonuses announced this year?\",\n",
        "\n",
        "    # Healthcare\n",
        "    \"What health insurance options does the company provide?\",\n",
        "    \"How do I add a dependent to my health insurance plan?\",\n",
        "    \"What is the process for filing a health insurance claim?\",\n",
        "    \"Are dental expenses covered under the company health plan?\",\n",
        "    \"How do I avail of mental health support through the company?\",\n",
        "    \"What is the coverage limit for outpatient services?\",\n",
        "    \"Does the company provide maternity benefits under health insurance?\",\n",
        "    \"What should I do in case of a medical emergency?\",\n",
        "    \"Are pre-existing conditions covered in the health insurance plan?\",\n",
        "    \"How can I check the list of network hospitals?\",\n",
        "    \"Can I opt-out of the company-provided health insurance?\",\n",
        "    \"What is the process to claim reimbursement for medical bills?\",\n",
        "    \"Does the company offer any wellness programs?\",\n",
        "    \"What are the benefits of the employee assistance program (EAP)?\",\n",
        "    \"Are vision expenses covered under our health insurance?\",\n",
        "    \"How do I check the status of my insurance claim?\",\n",
        "    \"Is there a cap on the number of claims I can make in a year?\",\n",
        "    \"How do I get a health card for my insurance plan?\",\n",
        "    \"What is the process for renewing health insurance annually?\",\n",
        "    \"Does the company cover alternative medicine treatments?\",\n",
        "\n",
        "    # Recruitment\n",
        "    \"How do I apply for an internal job posting?\",\n",
        "    \"What is the process for referring a candidate?\",\n",
        "    \"What is the status of my job application?\",\n",
        "    \"How long does the recruitment process usually take?\",\n",
        "    \"Are there any openings in the Marketing department?\",\n",
        "    \"What are the prerequisites for a promotion to a managerial role?\",\n",
        "    \"How does the company handle campus recruitments?\",\n",
        "    \"What is the procedure for scheduling an interview?\",\n",
        "    \"How can I prepare for the interview process?\",\n",
        "    \"Who do I contact for queries regarding my job application?\",\n",
        "    \"What is the selection process for an internship?\",\n",
        "    \"Can I apply for more than one position at a time?\",\n",
        "    \"What documents are required for the recruitment process?\",\n",
        "    \"How are background checks conducted for new hires?\",\n",
        "    \"Is there an aptitude test for the recruitment process?\",\n",
        "    \"How does the company decide on candidate shortlisting?\",\n",
        "    \"What are the benefits of internal job transfers?\",\n",
        "    \"Are there any recruitment events planned this year?\",\n",
        "    \"What is the probation period for new hires?\",\n",
        "    \"How is feedback provided to unsuccessful candidates?\",\n",
        "\n",
        "    # Training and Development\n",
        "    \"What training programs are available for employees?\",\n",
        "    \"How do I enroll in a professional development Ho?\",\n",
        "    \"Are there any mandatory training sessions this quarter?\",\n",
        "    \"How do I access the company's online learning portal?\",\n",
        "    \"What is the process for requesting external training?\",\n",
        "    \"Can I get certified through company-sponsored programs?\",\n",
        "    \"How is performance in training sessions evaluated?\",\n",
        "    \"Are there any upcoming workshops or seminars?\",\n",
        "    \"What are the leadership development opportunities available?\",\n",
        "    \"How do I provide feedback on a training session?\",\n",
        "    \"Can I request training in a specific skill area?\",\n",
        "    \"What is the company's policy on training leave?\",\n",
        "    \"How do I apply for a training reimbursement?\",\n",
        "    \"Are there any language learning courses provided?\",\n",
        "    \"What resources are available for self-paced learning?\",\n",
        "    \"How does the company ensure training effectiveness?\",\n",
        "    \"Can I suggest a new training program or course?\",\n",
        "    \"What is the process for accessing e-learning materials?\",\n",
        "    \"Are there any mentorship programs available?\",\n",
        "    \"How can I track my training progress?\",\n",
        "\n",
        "    # Performance Management\n",
        "    \"How is the performance appraisal process conducted?\",\n",
        "    \"What criteria are used for performance evaluations?\",\n",
        "    \"How do I set my performance goals for the year?\",\n",
        "    \"What should I do if I disagree with my performance rating?\",\n",
        "    \"How frequently are performance reviews conducted?\",\n",
        "    \"What is the process for getting feedback from my manager?\",\n",
        "    \"How does the company handle performance improvement plans?\",\n",
        "    \"Can I appeal against my performance evaluation results?\",\n",
        "    \"What are the key performance indicators (KPIs) for my role?\",\n",
        "    \"How are promotions and raises determined?\",\n",
        "    \"What is a 360-degree feedback process?\",\n",
        "    \"How do I prepare for my performance review meeting?\",\n",
        "    \"What training is available for performance management?\",\n",
        "    \"How does performance affect my bonus or incentive?\",\n",
        "    \"What is the role of self-assessment in the performance process?\",\n",
        "    \"Are there any templates available for setting SMART goals?\",\n",
        "    \"How do I request a performance review outside of the scheduled time?\",\n",
        "    \"What is the company's policy on underperformance?\",\n",
        "    \"How is team performance evaluated?\",\n",
        "    \"What happens after a performance improvement plan is completed?\",\n",
        "\n",
        "    # Employee Relations\n",
        "    \"How do I report workplace harassment?\",\n",
        "    \"What is the company's policy on workplace discrimination?\",\n",
        "    \"Who do I contact for conflict resolution in the workplace?\",\n",
        "    \"How does the company handle grievances?\",\n",
        "    \"What is the process for filing a formal complaint?\",\n",
        "    \"How does the company promote diversity and inclusion?\",\n",
        "    \"What is the whistleblower policy?\",\n",
        "    \"Can I anonymously report an issue at work?\",\n",
        "    \"How are interpersonal conflicts between employees managed?\",\n",
        "    \"What is the procedure for disciplinary action?\",\n",
        "    \"How do I request mediation for a workplace conflict?\",\n",
        "    \"What are my rights as an employee?\",\n",
        "    \"What support is available for mental health and wellbeing?\",\n",
        "    \"How is the company's code of conduct enforced?\",\n",
        "    \"What should I do if I experience bullying at work?\",\n",
        "    \"How are employee feedback and suggestions handled?\",\n",
        "    \"What is the role of the HR in managing employee relations?\",\n",
        "    \"How does the company handle retaliation claims?\",\n",
        "    \"What resources are available for understanding company policies?\",\n",
        "    \"How are exit interviews conducted?\",\n",
        "\n",
        "    # Benefits\n",
        "    \"What benefits are available to full-time employees?\",\n",
        "    \"How do I enroll in the company's retirement plan?\",\n",
        "    \"Are there any education benefits or scholarships for employees?\",\n",
        "    \"What is the process for availing employee discounts?\",\n",
        "    \"How do I check my benefits eligibility?\",\n",
        "    \"Are there any stock options available for employees?\",\n",
        "    \"What is the procedure for claiming travel benefits?\",\n",
        "    \"How does the company handle flexible work arrangements?\",\n",
        "    \"What are the childcare benefits offered by the company?\",\n",
        "    \"Can I get a loan from the company against my salary?\",\n",
        "    \"What are the benefits of the employee referral program?\",\n",
        "    \"How do I update my beneficiary information for insurance?\",\n",
        "    \"Are there any fitness or wellness benefits available?\",\n",
        "    \"How do I avail of the company's transportation benefits?\",\n",
        "    \"What is the policy on employee leave benefits?\",\n",
        "    \"Are there any relocation benefits for transferring employees?\",\n",
        "    \"How are long-term service awards distributed?\",\n",
        "    \"What kind of retirement planning support does the company provide?\",\n",
        "    \"Are there any benefits for part-time employees?\",\n",
        "    \"How are employee benefits communicated to new hires?\"\n",
        "]\n",
        "\n",
        "labels = [\n",
        "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, # Leaves\n",
        "    1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, # Payroll\n",
        "    2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, # Healthcare\n",
        "    3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, # Recruitment\n",
        "    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, # Training and Development\n",
        "    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, # Performance Management\n",
        "    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, # Employee Relations\n",
        "    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7  # Benefits\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9Lz6-6flIcFK",
        "outputId": "622e5e8a-bc5f-40a1-9900-695cb522b12e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.1212 - loss: 2.0806 - val_accuracy: 0.1250 - val_loss: 2.0797\n",
            "Epoch 2/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.1622 - loss: 2.0789 - val_accuracy: 0.1250 - val_loss: 2.0794\n",
            "Epoch 3/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1431 - loss: 2.0794 - val_accuracy: 0.1250 - val_loss: 2.0789\n",
            "Epoch 4/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.1462 - loss: 2.0774 - val_accuracy: 0.1562 - val_loss: 2.0786\n",
            "Epoch 5/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.2026 - loss: 2.0754 - val_accuracy: 0.1250 - val_loss: 2.0784\n",
            "Epoch 6/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.2128 - loss: 2.0744 - val_accuracy: 0.1562 - val_loss: 2.0781\n",
            "Epoch 7/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2364 - loss: 2.0732 - val_accuracy: 0.1562 - val_loss: 2.0780\n",
            "Epoch 8/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.2413 - loss: 2.0699 - val_accuracy: 0.1562 - val_loss: 2.0775\n",
            "Epoch 9/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.2557 - loss: 2.0700 - val_accuracy: 0.1562 - val_loss: 2.0770\n",
            "Epoch 10/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.2664 - loss: 2.0668 - val_accuracy: 0.1875 - val_loss: 2.0764\n",
            "Epoch 11/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.2420 - loss: 2.0672 - val_accuracy: 0.2188 - val_loss: 2.0756\n",
            "Epoch 12/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.3323 - loss: 2.0623 - val_accuracy: 0.1875 - val_loss: 2.0750\n",
            "Epoch 13/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3443 - loss: 2.0606 - val_accuracy: 0.2188 - val_loss: 2.0744\n",
            "Epoch 14/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3180 - loss: 2.0597 - val_accuracy: 0.2188 - val_loss: 2.0735\n",
            "Epoch 15/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.2921 - loss: 2.0582 - val_accuracy: 0.2500 - val_loss: 2.0725\n",
            "Epoch 16/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.3806 - loss: 2.0546 - val_accuracy: 0.2812 - val_loss: 2.0714\n",
            "Epoch 17/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3932 - loss: 2.0515 - val_accuracy: 0.3438 - val_loss: 2.0704\n",
            "Epoch 18/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.4987 - loss: 2.0428 - val_accuracy: 0.2812 - val_loss: 2.0693\n",
            "Epoch 19/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.3779 - loss: 2.0464 - val_accuracy: 0.3750 - val_loss: 2.0685\n",
            "Epoch 20/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5539 - loss: 2.0365 - val_accuracy: 0.2812 - val_loss: 2.0679\n",
            "Epoch 21/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4398 - loss: 2.0321 - val_accuracy: 0.2812 - val_loss: 2.0667\n",
            "Epoch 22/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4512 - loss: 2.0286 - val_accuracy: 0.3438 - val_loss: 2.0647\n",
            "Epoch 23/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 61ms/step - accuracy: 0.4937 - loss: 2.0167 - val_accuracy: 0.3125 - val_loss: 2.0636\n",
            "Epoch 24/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.5084 - loss: 2.0155 - val_accuracy: 0.2812 - val_loss: 2.0618\n",
            "Epoch 25/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5558 - loss: 2.0085 - val_accuracy: 0.3438 - val_loss: 2.0593\n",
            "Epoch 26/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5313 - loss: 2.0105 - val_accuracy: 0.3750 - val_loss: 2.0564\n",
            "Epoch 27/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6984 - loss: 1.9883 - val_accuracy: 0.3438 - val_loss: 2.0577\n",
            "Epoch 28/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6201 - loss: 1.9851 - val_accuracy: 0.3438 - val_loss: 2.0571\n",
            "Epoch 29/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5891 - loss: 1.9781 - val_accuracy: 0.3125 - val_loss: 2.0556\n",
            "Epoch 30/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6003 - loss: 1.9607 - val_accuracy: 0.3750 - val_loss: 2.0488\n",
            "Epoch 31/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7052 - loss: 1.9288 - val_accuracy: 0.3125 - val_loss: 2.0502\n",
            "Epoch 32/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5694 - loss: 1.9412 - val_accuracy: 0.2812 - val_loss: 2.0347\n",
            "Epoch 33/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6412 - loss: 1.9071 - val_accuracy: 0.2188 - val_loss: 2.0207\n",
            "Epoch 34/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5867 - loss: 1.8660 - val_accuracy: 0.1250 - val_loss: 2.0274\n",
            "Epoch 35/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.5698 - loss: 1.8601 - val_accuracy: 0.3438 - val_loss: 1.9829\n",
            "Epoch 36/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4801 - loss: 1.8281 - val_accuracy: 0.3125 - val_loss: 1.9794\n",
            "Epoch 37/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5870 - loss: 1.7949 - val_accuracy: 0.3125 - val_loss: 1.9287\n",
            "Epoch 38/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6581 - loss: 1.7340 - val_accuracy: 0.2812 - val_loss: 1.9668\n",
            "Epoch 39/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5434 - loss: 1.7013 - val_accuracy: 0.3438 - val_loss: 1.9313\n",
            "Epoch 40/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6009 - loss: 1.6527 - val_accuracy: 0.3750 - val_loss: 1.9118\n",
            "Epoch 41/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6570 - loss: 1.6034 - val_accuracy: 0.5625 - val_loss: 1.8400\n",
            "Epoch 42/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6520 - loss: 1.5932 - val_accuracy: 0.2500 - val_loss: 1.9316\n",
            "Epoch 43/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5326 - loss: 1.6069 - val_accuracy: 0.4688 - val_loss: 1.8254\n",
            "Epoch 44/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7276 - loss: 1.5134 - val_accuracy: 0.3438 - val_loss: 1.8541\n",
            "Epoch 45/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6686 - loss: 1.4746 - val_accuracy: 0.5000 - val_loss: 1.7951\n",
            "Epoch 46/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6977 - loss: 1.4608 - val_accuracy: 0.4688 - val_loss: 1.7721\n",
            "Epoch 47/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7088 - loss: 1.3610 - val_accuracy: 0.4688 - val_loss: 1.7299\n",
            "Epoch 48/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7455 - loss: 1.3511 - val_accuracy: 0.4688 - val_loss: 1.7817\n",
            "Epoch 49/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8207 - loss: 1.3095 - val_accuracy: 0.4375 - val_loss: 1.7053\n",
            "Epoch 50/50\n",
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7327 - loss: 1.3058 - val_accuracy: 0.5312 - val_loss: 1.7040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define maximum number of words and sequence length\n",
        "max_words = 2000  # Increase vocabulary size if needed\n",
        "max_sequence_length = 30  # Increase sequence length based on the longest text\n",
        "\n",
        "# Tokenizer for text to sequences\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Convert sentences to sequences of integers\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
        "\n",
        "# Number of categories\n",
        "num_categories = len(category_mapping)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the LSTM model with modified hyperparameters\n",
        "def create_lstm_model(input_dim, output_dim, embedding_dim=128, lstm_units=128, dropout_rate=0.5):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=input_dim, output_dim=embedding_dim, input_length=max_sequence_length),\n",
        "        LSTM(lstm_units, return_sequences=False, dropout=dropout_rate),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(output_dim, activation='softmax')  # Softmax for multi-class classification\n",
        "    ])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Input and output dimensions for the model\n",
        "input_dim = len(word_index) + 1  # Vocabulary size\n",
        "output_dim = num_categories  # Number of categories\n",
        "\n",
        "# Create the model with modified parameters\n",
        "embedding_dim = 128  # New embedding dimension\n",
        "lstm_units = 128     # Increase number of LSTM units\n",
        "dropout_rate = 0.5   # Higher dropout to avoid overfitting\n",
        "\n",
        "model = create_lstm_model(input_dim, output_dim, embedding_dim=embedding_dim, lstm_units=lstm_units, dropout_rate=dropout_rate)\n",
        "\n",
        "# Compile the model with a modified learning rate\n",
        "learning_rate = 0.0001  # Decrease learning rate for more refined training\n",
        "optimizer = Adam(learning_rate=learning_rate)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with a modified batch size and number of epochs\n",
        "batch_size = 16   # Increase batch size\n",
        "epochs = 50       # Train for more epochs\n",
        "\n",
        "model.fit(X_train, np.array(y_train), epochs=epochs, batch_size=batch_size, validation_data=(X_val, np.array(y_val)))\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save('updated_hr_chatbot_lstm_model.h5')\n",
        "\n",
        "import json\n",
        "with open('updated_tokenizer_config.json', 'w') as f:\n",
        "    json.dump(tokenizer.get_config(), f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iur-QNcUFPM",
        "outputId": "4d25b028-3865-44a7-e42f-3d4c92b484f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 30ms/step - accuracy: 0.7975 - loss: 1.1938 - val_accuracy: 0.5312 - val_loss: 1.6871\n",
            "Epoch 2/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7754 - loss: 1.2216 - val_accuracy: 0.5312 - val_loss: 1.6747\n",
            "Epoch 3/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8735 - loss: 1.1581 - val_accuracy: 0.5625 - val_loss: 1.6830\n",
            "Epoch 4/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.7161 - loss: 1.2786 - val_accuracy: 0.5312 - val_loss: 1.6907\n",
            "Epoch 5/5\n",
            "\u001b[1m64/64\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8371 - loss: 1.2021 - val_accuracy: 0.5312 - val_loss: 1.6729\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 316ms/step - accuracy: 0.5312 - loss: 1.6729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-Tuned Validation Loss: 1.6728949546813965\n",
            "Fine-Tuned Validation Accuracy: 0.53125\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the pre-trained model\n",
        "# Ensure the file name matches the saved model from the previous step\n",
        "model = load_model('updated_hr_chatbot_lstm_model.h5')\n",
        "\n",
        "# Optionally, freeze some layers (usually the embedding or earlier layers)\n",
        "# for layer in model.layers[:-2]:  # Freeze all layers except the last two\n",
        "#     layer.trainable = False\n",
        "\n",
        "# Compile the model again with a lower learning rate for fine-tuning\n",
        "# Typically you use a lower learning rate during fine-tuning to make small adjustments\n",
        "fine_tune_learning_rate = 1e-5\n",
        "model.compile(optimizer=Adam(learning_rate=fine_tune_learning_rate),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fine-tune the model on the training set (you can also use new data here)\n",
        "fine_tune_epochs = 5  # Set this to the number of epochs for fine-tuning\n",
        "history = model.fit(X_train, np.array(y_train),\n",
        "                    epochs=fine_tune_epochs,\n",
        "                    batch_size=2,\n",
        "                    validation_data=(X_val, np.array(y_val)))\n",
        "\n",
        "# Evaluate the fine-tuned model on the validation set\n",
        "val_loss, val_accuracy = model.evaluate(X_val, np.array(y_val))\n",
        "print(f\"Fine-Tuned Validation Loss: {val_loss}\")\n",
        "print(f\"Fine-Tuned Validation Accuracy: {val_accuracy}\")\n",
        "\n",
        "# Save the fine-tuned model\n",
        "model.save('fine_tuned_hr_chatbot_lstm_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmNv4Y4I7GLB",
        "outputId": "125e6923-3195-4446-b3b6-6d5463faac12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "Predicted Category: Employee Relations\n",
            "Model updated with new data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Predicted Category: Leaves\n",
            "Model updated with new data.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "Predicted Category: Leaves\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import json\n",
        "\n",
        "# Load the tokenizer configuration\n",
        "# Changed file path to 'updated_tokenizer_config.json'\n",
        "with open('updated_tokenizer_config.json', 'r') as f:\n",
        "    tokenizer_config = json.load(f)\n",
        "\n",
        "# Check if word_index is a string and convert it to a dictionary if necessary\n",
        "word_index_str = tokenizer_config.get('word_index', '{}')\n",
        "if isinstance(word_index_str, str):\n",
        "    word_index = json.loads(word_index_str)\n",
        "else:\n",
        "    word_index = word_index_str\n",
        "\n",
        "# Recreate the tokenizer\n",
        "tokenizer = Tokenizer(num_words=1000)\n",
        "tokenizer.word_index = word_index\n",
        "tokenizer.index_word = {v: k for k, v in tokenizer.word_index.items()}\n",
        "tokenizer.oov_token = tokenizer_config.get('oov_token', None)\n",
        "\n",
        "# Load the trained LSTM model, adjusting the file path and extension if needed\n",
        "# Changed file path to 'updated_hr_chatbot_lstm_model.h5'\n",
        "model = load_model('updated_hr_chatbot_lstm_model.h5')  # Change to '.h5' if that's how you saved it\n",
        "\n",
        "# Recompile the model with a new optimizer\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "category_mapping = {\n",
        "    0: \"Leaves\",\n",
        "    1: \"Payroll\",\n",
        "    2: \"Healthcare\",\n",
        "    3: \"Recruitment\",\n",
        "    4: \"Training and Development\",\n",
        "    5: \"Performance Management\",\n",
        "    6: \"Employee Relations\",\n",
        "    7: \"Benefits\"\n",
        "}\n",
        "\n",
        "num_categories = len(category_mapping)\n",
        "max_sequence_length = 20  # Should be the same as used in training\n",
        "\n",
        "# Function to preprocess a query\n",
        "def preprocess_query(query):\n",
        "    sequence = tokenizer.texts_to_sequences([query])\n",
        "    padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n",
        "    return padded_sequence\n",
        "\n",
        "# Function to classify a query and update the model\n",
        "def classify_and_update_model(model, query):\n",
        "    processed_query = preprocess_query(query)\n",
        "\n",
        "    # Predict the category\n",
        "    prediction = model.predict(processed_query)\n",
        "    predicted_category = np.argmax(prediction, axis=1)[0]\n",
        "\n",
        "    # Output the predicted category\n",
        "    print(f\"Predicted Category: {category_mapping[predicted_category]}\")\n",
        "\n",
        "    # Ask for user feedback\n",
        "    correct_category = input(\"Is this correct? (yes/no) If no, please provide the correct category: \")\n",
        "\n",
        "    if correct_category.lower() == 'no':\n",
        "        correct_category = int(input(f\"Enter the correct category number (0-{num_categories-1}): \"))\n",
        "    else:\n",
        "        correct_category = predicted_category\n",
        "\n",
        "    # Retrain the model with the new data (online learning)\n",
        "    # Note: Training with a single example may not be effective; consider batching data\n",
        "    model.fit(processed_query, np.array([correct_category]), epochs=100, batch_size=1, verbose=0)\n",
        "    print(\"Model updated with new data.\")\n",
        "\n",
        "    # Save the updated model in native Keras format\n",
        "    # Changed file path to 'updated_hr_chatbot_lstm_model.keras'\n",
        "    model.save('updated_hr_chatbot_lstm_model.keras')\n",
        "\n",
        "# Interactive loop\n",
        "while True:\n",
        "    user_query = input(\"Enter your query (or type 'exit' to stop): \")\n",
        "    if user_query.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    classify_and_update_model(model, user_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoLVZEQY9sHZ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNB9W2MyZRUF0ASMht37lcO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}